{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e69e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "\n",
    "def engineer_cifar_features(x_flat: np.ndarray) -> np.ndarray:\n",
    "    assert x_flat.ndim == 2 and x_flat.shape[1] == 3072, \"Expected (N, 3072)\"\n",
    "\n",
    "    N = x_flat.shape[0]\n",
    "\n",
    "    # Normalize to [0, 1]\n",
    "    x = x_flat.astype(np.float32) / 255.0\n",
    "\n",
    "    # Reshape to (N, 3, 32, 32)\n",
    "    x_img = x.reshape(N, 3, 32, 32)\n",
    "\n",
    "    # ---------- 1) Global color statistics ----------\n",
    "    # Mean and std per channel\n",
    "    ch_mean = x_img.mean(axis=(2, 3))           # (N, 3)\n",
    "    ch_std  = x_img.std(axis=(2, 3))            # (N, 3)\n",
    "\n",
    "    # ---------- 2) Global brightness / contrast (grayscale) ----------\n",
    "    # Standard luminance formula\n",
    "    gray = (\n",
    "        0.299 * x_img[:, 0] +\n",
    "        0.587 * x_img[:, 1] +\n",
    "        0.114 * x_img[:, 2]\n",
    "    )                                            # (N, 32, 32)\n",
    "\n",
    "    gray_mean = gray.mean(axis=(1, 2)).reshape(-1, 1)  # (N, 1)\n",
    "    gray_std  = gray.std(axis=(1, 2)).reshape(-1, 1)   # (N, 1)\n",
    "\n",
    "    # ---------- 3) 4x4 grid of grayscale means ----------\n",
    "    grid_size = 4\n",
    "    h_step = 32 // grid_size  # 8\n",
    "    w_step = 32 // grid_size  # 8\n",
    "\n",
    "    grid_feats = []\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            patch = gray[:, i*h_step:(i+1)*h_step, j*w_step:(j+1)*w_step]  # (N, 8, 8)\n",
    "            grid_feats.append(patch.mean(axis=(1, 2)))  # (N,)\n",
    "\n",
    "    grid_feats = np.stack(grid_feats, axis=1)   # (N, 16)\n",
    "\n",
    "    # ---------- 4) Color histograms (4 bins per channel) ----------\n",
    "    # Bins in [0,1]: [0, 0.25, 0.5, 0.75, 1.0]\n",
    "    bin_edges = np.array([0.0, 0.25, 0.5, 0.75, 1.01], dtype=np.float32)\n",
    "\n",
    "    hist_feats_list = []\n",
    "    for c in range(3):\n",
    "        ch_vals = x_img[:, c].reshape(N, -1)   # (N, 32*32)\n",
    "        hist_ch = []\n",
    "        for k in range(len(bin_edges) - 1):\n",
    "            mask = (ch_vals >= bin_edges[k]) & (ch_vals < bin_edges[k+1])\n",
    "            # relative frequency of pixels in this bin\n",
    "            hist_ch.append(mask.mean(axis=1))  # (N,)\n",
    "        hist_ch = np.stack(hist_ch, axis=1)    # (N, 4)\n",
    "        hist_feats_list.append(hist_ch)\n",
    "\n",
    "    hist_feats = np.concatenate(hist_feats_list, axis=1)  # (N, 12)\n",
    "\n",
    "    # ---------- Concatenate all features ----------\n",
    "    feats = np.concatenate(\n",
    "        [ch_mean, ch_std, gray_mean, gray_std, grid_feats, hist_feats],\n",
    "        axis=1\n",
    "    ).astype(np.float32)  # (N, 36)\n",
    "\n",
    "    return feats\n",
    "\n",
    "\n",
    "def cifar_to_tensors(\n",
    "    x_flat: np.ndarray,\n",
    "    y: np.ndarray,\n",
    "):\n",
    "    X_np = engineer_cifar_features(x_flat)         # (N, 36)\n",
    "    y_np = y.astype(np.int64)\n",
    "\n",
    "    X = torch.from_numpy(X_np)                     # float32\n",
    "    y_t = torch.from_numpy(y_np)                   # long\n",
    "\n",
    "    return X, y_t\n",
    "\n",
    "\n",
    "def cifar_torch_dataset(\n",
    "    x_flat: np.ndarray,\n",
    "    y: np.ndarray,\n",
    ") -> TensorDataset:\n",
    "    \"\"\"\n",
    "    Convenience wrapper returning a TensorDataset.\n",
    "    \"\"\"\n",
    "    X, y_t = cifar_to_tensors(x_flat, y)\n",
    "    return TensorDataset(X, y_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68919b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "def load_cifar_batch(path: str):\n",
    "    with open(path, \"rb\") as f:\n",
    "        batch = pickle.load(f, encoding=\"latin1\")\n",
    "    data = batch[\"data\"]\n",
    "    labels = np.array(batch[\"labels\"])\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "def load_cifar10(root: str):\n",
    "    xs, ys = [], []\n",
    "    for i in range(1, 6):\n",
    "        batch_path = os.path.join(root, f\"data_batch_{i}\")\n",
    "        x, y = load_cifar_batch(batch_path)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    x_train = np.concatenate(xs, axis=0)\n",
    "    y_train = np.concatenate(ys, axis=0)\n",
    "    x_test, y_test = load_cifar_batch(os.path.join(root, \"test_batch\"))\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfe690be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to ../data/cifar_dataset.pt\n",
      "Train set shape: X=torch.Size([50000, 36]), y=torch.Size([50000])\n",
      "Test set shape: X=torch.Size([10000, 36]), y=torch.Size([10000])\n",
      "Number of features: 36\n"
     ]
    }
   ],
   "source": [
    "CIFAR_ROOT = \"../data/cifar-10-batches-py\"\n",
    "OUTPUT_PATH = \"../data/cifar_dataset.pt\"\n",
    "\n",
    "x_train_raw, y_train_raw, x_test_raw, y_test_raw = load_cifar10(CIFAR_ROOT)\n",
    "\n",
    "X_train, y_train = cifar_to_tensors(x_train_raw, y_train_raw)\n",
    "\n",
    "X_test, y_test = cifar_to_tensors(x_test_raw, y_test_raw)\n",
    "\n",
    "torch.save({\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_test': X_test,\n",
    "    'y_test': y_test,\n",
    "    'classification': True,\n",
    "    'n_classes': 10,\n",
    "}, OUTPUT_PATH)\n",
    "\n",
    "print(f\"Dataset saved to {OUTPUT_PATH}\")\n",
    "print(f\"Train set shape: X={X_train.shape}, y={y_train.shape}\")\n",
    "print(f\"Test set shape: X={X_test.shape}, y={y_test.shape}\")\n",
    "print(f\"Number of features: {X_train.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca1fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-systems-labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
