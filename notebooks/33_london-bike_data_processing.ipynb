{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "\n",
        "def load_london_bike_dataframe(csv_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load london_merged.csv and do basic cleaning / typing.\"\"\"\n",
        "    df = pd.read_csv(csv_path, parse_dates=[\"timestamp\"])\n",
        "    df = df.sort_values(\"timestamp\").reset_index(drop=True)\n",
        "    return df\n",
        "\n",
        "\n",
        "def engineer_london_features(df: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Basic feature engineering for decision tree:\n",
        "    - extract time features from timestamp\n",
        "    - simple derived features from existing columns\n",
        "    \"\"\"\n",
        "\n",
        "    df_feat = df.copy()\n",
        "\n",
        "    # --- time features ---\n",
        "    df_feat[\"hour\"] = df_feat[\"timestamp\"].dt.hour\n",
        "    df_feat[\"dayofweek\"] = df_feat[\"timestamp\"].dt.dayofweek  # 0 = Monday\n",
        "    df_feat[\"month\"] = df_feat[\"timestamp\"].dt.month\n",
        "    df_feat[\"year\"] = df_feat[\"timestamp\"].dt.year\n",
        "\n",
        "    # peak commuting hours (7–9 and 16–19)\n",
        "    df_feat[\"is_peak_hour\"] = (\n",
        "        ((df_feat[\"hour\"] >= 7) & (df_feat[\"hour\"] <= 9)) |\n",
        "        ((df_feat[\"hour\"] >= 16) & (df_feat[\"hour\"] <= 19))\n",
        "    ).astype(int)\n",
        "\n",
        "    # temp difference: how much \"feels like\" differs from actual\n",
        "    df_feat[\"temp_diff\"] = df_feat[\"t1\"] - df_feat[\"t2\"]\n",
        "\n",
        "    # we don't want the raw timestamp column as a feature\n",
        "    df_feat = df_feat.drop(columns=[\"timestamp\"])\n",
        "\n",
        "    return df_feat\n",
        "\n",
        "\n",
        "def london_bike_to_tensors(\n",
        "    csv_path: str,\n",
        "    classification: bool = False,\n",
        "    n_classes: int = 3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Load London bike data, do feature engineering and return\n",
        "    (X_tensor, y_tensor, feature_names).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    csv_path : str\n",
        "        Path to london_merged.csv\n",
        "    classification : bool\n",
        "        If True, y is a class label (0..n_classes-1) created from binned `cnt`.\n",
        "        If False, y is the raw `cnt` (regression).\n",
        "    n_classes : int\n",
        "        Number of bins for classification (default 3: low / medium / high).\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    X : torch.FloatTensor of shape (N, n_features)\n",
        "    y : torch.Tensor  (LongTensor for classification, FloatTensor for regression)\n",
        "    feature_names : list[str]\n",
        "    \"\"\"\n",
        "\n",
        "    df_raw = load_london_bike_dataframe(csv_path)\n",
        "    df_feat = engineer_london_features(df_raw)\n",
        "\n",
        "    # target column\n",
        "    cnt = df_feat[\"cnt\"].copy()\n",
        "\n",
        "    # drop target from features\n",
        "    df_feat = df_feat.drop(columns=[\"cnt\"])\n",
        "\n",
        "    feature_names = list(df_feat.columns)\n",
        "\n",
        "    # convert features to float32 matrix\n",
        "    X = df_feat.to_numpy(dtype=np.float32)\n",
        "\n",
        "    if classification:\n",
        "        # bin cnt into n_classes roughly equal-sized groups\n",
        "        # qcut may fail if there are many duplicates at bin edges, so we guard it\n",
        "        try:\n",
        "            y_bins = pd.qcut(cnt, q=n_classes, labels=False, duplicates=\"drop\")\n",
        "        except ValueError:\n",
        "            # fallback: cut by uniform width if qcut fails\n",
        "            y_bins = pd.cut(cnt, bins=n_classes, labels=False)\n",
        "\n",
        "        y = y_bins.to_numpy(dtype=np.int64)\n",
        "        y_tensor = torch.from_numpy(y)  # LongTensor\n",
        "    else:\n",
        "        # regression target\n",
        "        y = cnt.to_numpy(dtype=np.float32)\n",
        "        y_tensor = torch.from_numpy(y)  # FloatTensor\n",
        "\n",
        "    X_tensor = torch.from_numpy(X)\n",
        "\n",
        "    return X_tensor, y_tensor, feature_names\n",
        "\n",
        "\n",
        "def london_bike_torch_dataset(\n",
        "    csv_path: str,\n",
        "    classification: bool = False,\n",
        "    n_classes: int = 3,\n",
        ") -> TensorDataset:\n",
        "    \"\"\"\n",
        "    Convenience wrapper that returns a TensorDataset.\n",
        "    \"\"\"\n",
        "    X, y, _ = london_bike_to_tensors(csv_path, classification=classification, n_classes=n_classes)\n",
        "    return TensorDataset(X, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset saved to ../data/london_bike_dataset.pt\n",
            "Dataset shape: X=torch.Size([17414, 14]), y=torch.Size([17414])\n",
            "Number of features: 14\n",
            "Feature names: ['t1', 't2', 'hum', 'wind_speed', 'weather_code', 'is_holiday', 'is_weekend', 'season', 'hour', 'dayofweek', 'month', 'year', 'is_peak_hour', 'temp_diff']\n"
          ]
        }
      ],
      "source": [
        "# Process data and save torch dataset\n",
        "CSV_PATH = \"../data/london_merged.csv\"\n",
        "OUTPUT_PATH = \"../data/london_bike_dataset.pt\"\n",
        "\n",
        "# Load and process data\n",
        "X_reg, y_reg, feat_names = london_bike_to_tensors(CSV_PATH, classification=False)\n",
        "\n",
        "# Create dataset\n",
        "dataset = TensorDataset(X_reg, y_reg)\n",
        "\n",
        "# Save dataset\n",
        "torch.save({\n",
        "    'X': X_reg,\n",
        "    'y': y_reg,\n",
        "    'feature_names': feat_names,\n",
        "    'classification': False,\n",
        "}, OUTPUT_PATH)\n",
        "\n",
        "print(f\"Dataset saved to {OUTPUT_PATH}\")\n",
        "print(f\"Dataset shape: X={X_reg.shape}, y={y_reg.shape}\")\n",
        "print(f\"Number of features: {len(feat_names)}\")\n",
        "print(f\"Feature names: {feat_names}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-systems-labs",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
